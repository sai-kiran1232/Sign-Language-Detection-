{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "bwyRbz84eVbe",
        "outputId": "4c7b138c-4bde-4f27-fe80-3bd27079908e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "DATA COLLECTION"
      ],
      "metadata": {
        "id": "uaPWO5TL6u2n"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "kV_3qBv0eGVD"
      },
      "outputs": [],
      "source": [
        "#Import Necessary Libraries\n",
        "import os\n",
        "from keras.models import load_model\n",
        "from PIL import Image, ImageOps\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Path to the folder in Google Drive\n",
        "folder_path = '/content/drive/My Drive/Hand_Gesture_Recognition'"
      ],
      "metadata": {
        "id": "A2yjUKr2epBQ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# List files in the folder\n",
        "for filename in os.listdir(folder_path):\n",
        "    print(filename)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "l43jIzrDfvzc",
        "outputId": "244808b5-3ef6-4148-e87a-9852bae24d0f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IMG_20220430_180531.jpg\n",
            "IMG_20220430_181802.jpg\n",
            "IMG_20220430_181203.jpg\n",
            "IMG_20220430_181910.jpg\n",
            "IMG_20220430_181815.jpg\n",
            "IMG_20220430_181905.jpg\n",
            "IMG_20220430_181919.jpg\n",
            "IMG_20220430_180307.jpg\n",
            "labels.txt\n",
            "keras_model.h5\n",
            "154e771368e8e6e3395097fa59b410c3.jpg\n",
            "istockphoto-181436588-612x612.jpg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "LOAD THE KERAS MODEL AND LABELS\n"
      ],
      "metadata": {
        "id": "801USe4l6x0R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the model\n",
        "model_path = os.path.join(folder_path, \"keras_model.h5\")\n",
        "model = load_model(model_path, compile=False)"
      ],
      "metadata": {
        "id": "5Vqg8fTPgEzP"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the labels\n",
        "labels_path = os.path.join(folder_path, \"labels.txt\")\n",
        "class_names = open(labels_path, \"r\").readlines()"
      ],
      "metadata": {
        "id": "QlKnTSPSgN_w"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "DATA PREPROCESSING"
      ],
      "metadata": {
        "id": "-UBWImo065ro"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Disable scientific notation for clarity\n",
        "np.set_printoptions(suppress=True)"
      ],
      "metadata": {
        "id": "D3KzlYfZg_Om"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the array of the right shape to feed into the keras model\n",
        "data = np.ndarray(shape=(1, 224, 224, 3), dtype=np.float32)"
      ],
      "metadata": {
        "id": "wd_X6h6khBg4"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_path = '/content/drive/My Drive/Hand_Gesture_Recognition/istockphoto-181436588-612x612.jpg'\n",
        "image = Image.open(image_path).convert(\"RGB\")"
      ],
      "metadata": {
        "id": "vnAemA4khEC4"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Resize the image to be at least 224x224 and then crop from the center\n",
        "size = (224, 224)\n",
        "image = ImageOps.fit(image, size, Image.Resampling.LANCZOS)"
      ],
      "metadata": {
        "id": "xTxGsiSWhkxz"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Turn the image into a numpy array\n",
        "image_array = np.asarray(image)"
      ],
      "metadata": {
        "id": "LUaRfq0uhm5Z"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize the image\n",
        "normalized_image_array = (image_array.astype(np.float32) / 127.5) - 1"
      ],
      "metadata": {
        "id": "eLNzBmLGhpFC"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the image into the array\n",
        "data[0] = normalized_image_array"
      ],
      "metadata": {
        "id": "qo60a--1hrep"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "BUILDING A PREDICTIVE ANALYSIS"
      ],
      "metadata": {
        "id": "_lMdyGZR6_6G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict the model\n",
        "prediction = model.predict(data)\n",
        "index = np.argmax(prediction)\n",
        "class_name = class_names[index]\n",
        "confidence_score = prediction[0][index]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "oIikee_ThtfV",
        "outputId": "a47e5cfb-2987-43a3-8129-19d6fd53b99a"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 1s/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print prediction and confidence score\n",
        "print(\"Class:\", class_name.strip())\n",
        "print(\"Confidence Score:\", confidence_score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "QNXsT02OhwPI",
        "outputId": "2f475d1c-d24f-4693-badd-52b9ad73ab06"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class: 3 thumsdown\n",
            "Confidence Score: 0.9999578\n"
          ]
        }
      ]
    }
  ]
}